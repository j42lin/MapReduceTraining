Meta VERSION="1" .
Job JOBID="job_201504171631_0007" JOBNAME="streamjob8809397114730110011\.jar" USER="training" SUBMIT_TIME="1429305450912" JOBCONF="hdfs://0\.0\.0\.0:8020/var/lib/hadoop-hdfs/cache/mapred/mapred/staging/training/\.staging/job_201504171631_0007/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201504171631_0007" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201504171631_0007" LAUNCH_TIME="1429305451080" TOTAL_MAPS="8" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201504171631_0007_m_000009" TASK_TYPE="SETUP" START_TIME="1429305451082" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201504171631_0007_m_000009" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000009_0" START_TIME="1429305451212" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201504171631_0007_m_000009" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305452952" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(42983424)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386060288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000009" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305453200" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(42983424)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386060288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201504171631_0007" JOB_STATUS="RUNNING" .
Task TASKID="task_201504171631_0007_m_000000" TASK_TYPE="MAP" START_TIME="1429305453201" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201504171631_0007_m_000001" TASK_TYPE="MAP" START_TIME="1429305453202" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000000" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000000_0" START_TIME="1429305453204" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000000" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305479528" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=382942/381403" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36932509)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74053150)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113057)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600016)][(MAP_OUTPUT_RECORDS)(Map output records)(600016)][(MAP_OUTPUT_BYTES)(Map output bytes)(35731932)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1200032)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8190)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194514944)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108974)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305479665" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36932509)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74053150)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113057)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600016)][(MAP_OUTPUT_RECORDS)(Map output records)(600016)][(MAP_OUTPUT_BYTES)(Map output bytes)(35731932)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1200032)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8190)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194514944)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108974)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000002" TASK_TYPE="MAP" START_TIME="1429305479665" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201504171631_0007_r_000000" TASK_TYPE="REDUCE" START_TIME="1429305479666" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000001" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000001_0" START_TIME="1429305453204" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000001" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305480665" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=381200/379471" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36782338)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(73752808)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600754)][(MAP_OUTPUT_RECORDS)(Map output records)(600751)][(MAP_OUTPUT_BYTES)(Map output bytes)(35580554)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1201502)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8130)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194846720)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108782)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305480941" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36782338)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(73752808)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600754)][(MAP_OUTPUT_RECORDS)(Map output records)(600751)][(MAP_OUTPUT_BYTES)(Map output bytes)(35580554)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1201502)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8130)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194846720)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108782)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000003" TASK_TYPE="MAP" START_TIME="1429305480942" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000002" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000002_0" START_TIME="1429305479671" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000002" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305503049" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=459024/457225" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36962058)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74112248)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596105)][(MAP_OUTPUT_RECORDS)(Map output records)(596105)][(MAP_OUTPUT_BYTES)(Map output bytes)(35769589)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1192210)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7760)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194289664)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305503284" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36962058)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74112248)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596105)][(MAP_OUTPUT_RECORDS)(Map output records)(596105)][(MAP_OUTPUT_BYTES)(Map output bytes)(35769589)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1192210)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7760)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194289664)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000004" TASK_TYPE="MAP" START_TIME="1429305503286" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000003" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000003_0" START_TIME="1429305480949" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000003" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305503660" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=455032/453469" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(37473018)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(75134168)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(586103)][(MAP_OUTPUT_RECORDS)(Map output records)(586101)][(MAP_OUTPUT_BYTES)(Map output bytes)(36299796)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1172202)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(193679360)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305503892" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(37473018)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(75134168)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(586103)][(MAP_OUTPUT_RECORDS)(Map output records)(586101)][(MAP_OUTPUT_BYTES)(Map output bytes)(36299796)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1172202)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(193679360)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000005" TASK_TYPE="MAP" START_TIME="1429305503893" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000004" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000004_0" START_TIME="1429305503288" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000004" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305528104" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=447432/446743" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(37293659)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74775450)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(590850)][(MAP_OUTPUT_RECORDS)(Map output records)(590844)][(MAP_OUTPUT_BYTES)(Map output bytes)(36110357)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1181688)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7670)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194428928)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108878)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305528322" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(37293659)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74775450)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(590850)][(MAP_OUTPUT_RECORDS)(Map output records)(590844)][(MAP_OUTPUT_BYTES)(Map output bytes)(36110357)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1181688)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7670)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194428928)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108878)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000005" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000005_0" START_TIME="1429305503894" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000005" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305528097" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=464598/463196" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36986831)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74161794)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596948)][(MAP_OUTPUT_RECORDS)(Map output records)(596935)][(MAP_OUTPUT_BYTES)(Map output bytes)(35791966)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1193870)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194646016)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108834)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305528324" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(36986831)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74161794)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596948)][(MAP_OUTPUT_RECORDS)(Map output records)(596935)][(MAP_OUTPUT_BYTES)(Map output bytes)(35791966)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1193870)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194646016)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108834)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000006" TASK_TYPE="MAP" START_TIME="1429305528325" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201504171631_0007_m_000007" TASK_TYPE="MAP" START_TIME="1429305528325" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000007" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000007_0" START_TIME="1429305528328" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000007" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305550415" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1159/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(19389578)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(38967294)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(35179582)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(313258)][(MAP_OUTPUT_RECORDS)(Map output records)(313257)][(MAP_OUTPUT_BYTES)(Map output bytes)(18762367)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(626514)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(5480)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(187215872)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388337664)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(35179391)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305550521" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(19389578)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(38967294)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(35179582)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(313258)][(MAP_OUTPUT_RECORDS)(Map output records)(313257)][(MAP_OUTPUT_BYTES)(Map output bytes)(18762367)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(626514)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(5480)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(187215872)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388337664)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(35179391)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000006" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000006_0" START_TIME="1429305528327" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504171631_0007_m_000006" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305555964" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=335771/334379" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(37142076)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74472284)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(593809)][(MAP_OUTPUT_RECORDS)(Map output records)(593781)][(MAP_OUTPUT_BYTES)(Map output bytes)(35951750)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1187562)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(9140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(193777664)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388337664)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108950)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305556136" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(37142076)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(74472284)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(593809)][(MAP_OUTPUT_RECORDS)(Map output records)(593781)][(MAP_OUTPUT_BYTES)(Map output bytes)(35951750)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1187562)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(9140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(193777664)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388337664)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108950)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201504171631_0007_r_000000" TASK_ATTEMPT_ID="attempt_201504171631_0007_r_000000_0" START_TIME="1429305479674" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201504171631_0007_r_000000" TASK_ATTEMPT_ID="attempt_201504171631_0007_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1429305556754" SORT_FINISHED="1429305558912" FINISH_TIME="1429305579119" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=2611350/32195 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(278961977)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(279149697)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(4935311)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(63060)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(278961977)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(63061)][(SPILLED_RECORDS)(Spilled Records)(4477790)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(19650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(68923392)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(389726208)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(35708928)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1429305579400" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(278961977)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(279149697)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(4935311)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(63060)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(278961977)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(63061)][(SPILLED_RECORDS)(Spilled Records)(4477790)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(19650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(68923392)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(389726208)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(35708928)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000008" TASK_TYPE="CLEANUP" START_TIME="1429305579401" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201504171631_0007_m_000008" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000008_0" START_TIME="1429305579405" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:56067" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201504171631_0007_m_000008" TASK_ATTEMPT_ID="attempt_201504171631_0007_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429305581199" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(90)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(43372544)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386392064)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504171631_0007_m_000008" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1429305581212" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(90)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(43372544)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386392064)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201504171631_0007" FINISH_TIME="1429305581213" JOB_STATUS="SUCCESS" FINISHED_MAPS="8" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(278962067)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(559429196)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(504970987)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(16)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4477843)][(MAP_OUTPUT_RECORDS)(Map output records)(4477790)][(MAP_OUTPUT_BYTES)(Map output bytes)(269998311)][(SPLIT_RAW_BYTES)(Input split bytes)(776)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8955580)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(61720)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(1547399168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(3105742848)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1286111232)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(504941532)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(278961977)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(279149697)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(4935311)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(63060)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(278961977)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(63061)][(SPILLED_RECORDS)(Spilled Records)(4477790)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(19650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(68923392)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(389726208)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(35708928)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(557924044)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(838578893)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(504970987)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(4935311)][(HDFS_READ_OPS)(HDFS: Number of read operations)(17)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(8)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(8)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(202151)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(99445)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4477843)][(MAP_OUTPUT_RECORDS)(Map output records)(4477790)][(MAP_OUTPUT_BYTES)(Map output bytes)(269998311)][(SPLIT_RAW_BYTES)(Input split bytes)(776)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(63060)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(278961977)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(63061)][(SPILLED_RECORDS)(Spilled Records)(13433370)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(81370)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(1616322560)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(3495469056)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1321820160)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(504941532)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
