Meta VERSION="1" .
Job JOBID="job_201504172218_0014" JOBNAME="streamjob6530177830262958178\.jar" USER="training" SUBMIT_TIME="1429331336294" JOBCONF="hdfs://0\.0\.0\.0:8020/var/lib/hadoop-hdfs/cache/mapred/mapred/staging/training/\.staging/job_201504172218_0014/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201504172218_0014" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201504172218_0014" LAUNCH_TIME="1429331336836" TOTAL_MAPS="8" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201504172218_0014_m_000009" TASK_TYPE="SETUP" START_TIME="1429331336947" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201504172218_0014_m_000009" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000009_0" START_TIME="1429331337136" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201504172218_0014_m_000009" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331338765" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(42926080)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386060288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000009" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331339062" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(42926080)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386060288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201504172218_0014" JOB_STATUS="RUNNING" .
Task TASKID="task_201504172218_0014_m_000000" TASK_TYPE="MAP" START_TIME="1429331339081" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201504172218_0014_m_000001" TASK_TYPE="MAP" START_TIME="1429331339081" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000001" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000001_0" START_TIME="1429331339084" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000001" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331372708" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=492250/491346" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(28876439)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(57941010)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600754)][(MAP_OUTPUT_RECORDS)(Map output records)(600751)][(MAP_OUTPUT_BYTES)(Map output bytes)(27674744)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1201502)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13920)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195072000)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388333568)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108782)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331373012" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(28876439)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(57941010)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600754)][(MAP_OUTPUT_RECORDS)(Map output records)(600751)][(MAP_OUTPUT_BYTES)(Map output bytes)(27674744)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1201502)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13920)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195072000)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388333568)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108782)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000002" TASK_TYPE="MAP" START_TIME="1429331373013" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201504172218_0014_r_000000" TASK_TYPE="REDUCE" START_TIME="1429331373014" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000000" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000000_0" START_TIME="1429331339084" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000000" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331373488" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=456231/454395" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29124913)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(58437958)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113057)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600016)][(MAP_OUTPUT_RECORDS)(Map output records)(600016)][(MAP_OUTPUT_BYTES)(Map output bytes)(27924343)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1200032)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13640)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195108864)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388333568)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108974)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331373624" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29124913)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(58437958)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113057)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600016)][(MAP_OUTPUT_RECORDS)(Map output records)(600016)][(MAP_OUTPUT_BYTES)(Map output bytes)(27924343)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1200032)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13640)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195108864)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388333568)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108974)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000003" TASK_TYPE="MAP" START_TIME="1429331373627" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000003" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000003_0" START_TIME="1429331373633" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000003" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331408425" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=459441/457941" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29801312)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(59790756)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(586103)][(MAP_OUTPUT_RECORDS)(Map output records)(586101)][(MAP_OUTPUT_BYTES)(Map output bytes)(28628161)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1172202)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(12260)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195346432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331408553" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29801312)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(59790756)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(586103)][(MAP_OUTPUT_RECORDS)(Map output records)(586101)][(MAP_OUTPUT_BYTES)(Map output bytes)(28628161)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1172202)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(12260)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195346432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000004" TASK_TYPE="MAP" START_TIME="1429331408554" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000002" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000002_0" START_TIME="1429331373022" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000002" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331408624" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=459024/457595" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29156486)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(58501104)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596105)][(MAP_OUTPUT_RECORDS)(Map output records)(596105)][(MAP_OUTPUT_BYTES)(Map output bytes)(27964072)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1192210)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195260416)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331408857" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29156486)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(58501104)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596105)][(MAP_OUTPUT_RECORDS)(Map output records)(596105)][(MAP_OUTPUT_BYTES)(Map output bytes)(27964072)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1192210)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195260416)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000005" TASK_TYPE="MAP" START_TIME="1429331408861" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000005" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000005_0" START_TIME="1429331408865" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000005" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331443644" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=457570/456449" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29170463)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(58529058)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596948)][(MAP_OUTPUT_RECORDS)(Map output records)(596935)][(MAP_OUTPUT_BYTES)(Map output bytes)(27975736)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1193870)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(11780)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194625536)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108834)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331443742" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29170463)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(58529058)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596948)][(MAP_OUTPUT_RECORDS)(Map output records)(596935)][(MAP_OUTPUT_BYTES)(Map output bytes)(27975736)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1193870)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(11780)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194625536)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108834)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000006" TASK_TYPE="MAP" START_TIME="1429331443743" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000004" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000004_0" START_TIME="1429331408560" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000004" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331448211" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=356527/354916" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29542618)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(59273368)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(590850)][(MAP_OUTPUT_RECORDS)(Map output records)(590844)][(MAP_OUTPUT_BYTES)(Map output bytes)(28359646)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1181688)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(12590)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195330048)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388349952)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108878)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331448278" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29542618)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(59273368)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(590850)][(MAP_OUTPUT_RECORDS)(Map output records)(590844)][(MAP_OUTPUT_BYTES)(Map output bytes)(28359646)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1181688)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(12590)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195330048)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388349952)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108878)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000007" TASK_TYPE="MAP" START_TIME="1429331448279" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000007" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000007_0" START_TIME="1429331448280" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000007" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331471172" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=273822/272060" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(15313588)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(30815314)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(35179582)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(313258)][(MAP_OUTPUT_RECORDS)(Map output records)(313257)][(MAP_OUTPUT_BYTES)(Map output bytes)(14686391)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(626514)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6970)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(186851328)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(35179391)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331471324" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(15313588)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(30815314)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(35179582)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(313258)][(MAP_OUTPUT_RECORDS)(Map output records)(313257)][(MAP_OUTPUT_BYTES)(Map output bytes)(14686391)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(626514)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6970)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(186851328)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(35179391)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000006" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000006_0" START_TIME="1429331443749" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201504172218_0014_m_000006" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331479409" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=512954/511351" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29415760)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(59019652)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(593809)][(MAP_OUTPUT_RECORDS)(Map output records)(593781)][(MAP_OUTPUT_BYTES)(Map output bytes)(28225442)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1187562)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(14000)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194150400)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108950)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331479489" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(29415760)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(59019652)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113058)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(593809)][(MAP_OUTPUT_RECORDS)(Map output records)(593781)][(MAP_OUTPUT_BYTES)(Map output bytes)(28225442)][(SPLIT_RAW_BYTES)(Input split bytes)(97)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1187562)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(14000)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194150400)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108950)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201504172218_0014_r_000000" TASK_ATTEMPT_ID="attempt_201504172218_0014_r_000000_0" START_TIME="1429331373025" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201504172218_0014_r_000000" TASK_ATTEMPT_ID="attempt_201504172218_0014_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1429331482453" SORT_FINISHED="1429331484182" FINISH_TIME="1429331507887" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=2279608/22388 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(220401459)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(220589179)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(2700138)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42027)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(220401489)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(42028)][(SPILLED_RECORDS)(Spilled Records)(4477790)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(23700)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(217165824)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(390676480)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184205312)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1429331507903" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(220401459)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(220589179)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(2700138)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42027)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(220401489)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(42028)][(SPILLED_RECORDS)(Spilled Records)(4477790)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(23700)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(217165824)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(390676480)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184205312)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000008" TASK_TYPE="CLEANUP" START_TIME="1429331507906" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201504172218_0014_m_000008" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000008_0" START_TIME="1429331507912" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:44906" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201504172218_0014_m_000008" TASK_ATTEMPT_ID="attempt_201504172218_0014_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1429331510120" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(110)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(43298816)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386392064)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201504172218_0014_m_000008" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1429331510326" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188112)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(110)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(43298816)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386392064)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201504172218_0014" FINISH_TIME="1429331510327" JOB_STATUS="SUCCESS" FINISHED_MAPS="8" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(220401579)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(442308220)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(504970987)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(16)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4477843)][(MAP_OUTPUT_RECORDS)(Map output records)(4477790)][(MAP_OUTPUT_BYTES)(Map output bytes)(211438535)][(SPLIT_RAW_BYTES)(Input split bytes)(776)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8955580)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(98300)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(1551745024)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(3105906688)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1286111232)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(504941532)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(220401459)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(220589179)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(2700138)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42027)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(220401489)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(42028)][(SPILLED_RECORDS)(Spilled Records)(4477790)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(23700)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(217165824)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(390676480)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184205312)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(440803038)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(662897399)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(504970987)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(2700138)][(HDFS_READ_OPS)(HDFS: Number of read operations)(17)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(8)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(8)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(275241)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(134862)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4477843)][(MAP_OUTPUT_RECORDS)(Map output records)(4477790)][(MAP_OUTPUT_BYTES)(Map output bytes)(211438535)][(SPLIT_RAW_BYTES)(Input split bytes)(776)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42027)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(220401489)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477790)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(42028)][(SPILLED_RECORDS)(Spilled Records)(13433370)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(122000)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(1768910848)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(3496583168)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1470316544)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(504941532)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
